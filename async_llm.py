import asyncio
import random
import os
from config import API_PROVIDER, API_KEY, API_BASE, MODEL_NAME, MAX_RETRY, USE_PROXY, PROXY_URL, GEMINI_SAFETY_SETTINGS

# é…ç½®ä»£ç†
if USE_PROXY and PROXY_URL:
    os.environ['HTTP_PROXY'] = PROXY_URL
    os.environ['HTTPS_PROXY'] = PROXY_URL
    print(f"ğŸŒ å·²é…ç½®ä»£ç†: {PROXY_URL}")

# å…¨å±€å˜é‡ï¼šGemini å®‰å…¨è®¾ç½®
gemini_safety_settings = None

# æ ¹æ® API_PROVIDER åˆå§‹åŒ–å®¢æˆ·ç«¯
if API_PROVIDER == "gemini":
    try:
        import google.generativeai as genai
        # Gemini API é€šè¿‡ç¯å¢ƒå˜é‡ä½¿ç”¨ä»£ç†
        genai.configure(api_key=API_KEY)
        
        # é…ç½®å®‰å…¨è®¾ç½®
        safety_mapping = {
            "BLOCK_NONE": genai.types.HarmBlockThreshold.BLOCK_NONE,
            "BLOCK_ONLY_HIGH": genai.types.HarmBlockThreshold.BLOCK_ONLY_HIGH,
            "BLOCK_MEDIUM_AND_ABOVE": genai.types.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            "BLOCK_LOW_AND_ABOVE": genai.types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
        }
        safety_threshold = safety_mapping.get(GEMINI_SAFETY_SETTINGS, genai.types.HarmBlockThreshold.BLOCK_ONLY_HIGH)
        
        # åˆ›å»ºå®‰å…¨è®¾ç½®é…ç½®
        gemini_safety_settings = [
            {
                "category": genai.types.HarmCategory.HARM_CATEGORY_HARASSMENT,
                "threshold": safety_threshold,
            },
            {
                "category": genai.types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,
                "threshold": safety_threshold,
            },
            {
                "category": genai.types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
                "threshold": safety_threshold,
            },
            {
                "category": genai.types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
                "threshold": safety_threshold,
            },
        ]
        
        print(f"âœ… Gemini API åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {MODEL_NAME})")
        print(f"   â„¹ï¸  å®‰å…¨è®¾ç½®: {GEMINI_SAFETY_SETTINGS}")
        if USE_PROXY and PROXY_URL:
            print(f"   â„¹ï¸  Gemini API å°†é€šè¿‡ç¯å¢ƒå˜é‡ä½¿ç”¨ä»£ç†")
    except ImportError:
        print("âŒ é”™è¯¯: æœªå®‰è£… google-generativeai åº“")
        print("ğŸ’¡ è¯·è¿è¡Œ: pip install google-generativeai")
        raise
    except Exception as e:
        print(f"âŒ Gemini API é…ç½®å¤±è´¥: {e}")
        raise
else:
    try:
        from openai import AsyncOpenAI
        # OpenAI å®¢æˆ·ç«¯æ”¯æŒé€šè¿‡ http_client é…ç½®ä»£ç†
        import httpx
        http_client = None
        if USE_PROXY and PROXY_URL:
            http_client = httpx.AsyncClient(proxies=PROXY_URL)
            print(f"ğŸŒ OpenAI å®¢æˆ·ç«¯å·²é…ç½®ä»£ç†: {PROXY_URL}")
        
        if API_BASE:
            openai_client = AsyncOpenAI(api_key=API_KEY, base_url=API_BASE, http_client=http_client)
        else:
            openai_client = AsyncOpenAI(api_key=API_KEY, http_client=http_client)
        print(f"âœ… OpenAI API åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {MODEL_NAME})")
    except ImportError as e:
        print("âŒ é”™è¯¯: æœªå®‰è£… openai åº“")
        print("ğŸ’¡ è¯·è¿è¡Œ: pip install openai")
        raise


async def call_llm_openai(prompt, chunk_id=None):
    """è°ƒç”¨ OpenAI å…¼å®¹ API"""
    chunk_info = f" [å— {chunk_id}]" if chunk_id else ""
    for attempt in range(MAX_RETRY):
        try:
            if attempt == 0:
                print(f"  ğŸ”„ è°ƒç”¨ OpenAI API{chunk_info}...")
            res = await openai_client.chat.completions.create(
                model=MODEL_NAME,
                messages=[{"role": "user", "content": prompt}],
                timeout=60,
            )
            result = res.choices[0].message.content
            print(f"  âœ… OpenAI API è°ƒç”¨æˆåŠŸ{chunk_info}")
            return result
        except Exception as e:
            wait = (2 ** attempt) + random.random()
            print(f"  âš ï¸ è°ƒç”¨å¤±è´¥{chunk_info}ï¼Œ{wait:.1f}s åé‡è¯• (å°è¯• {attempt + 1}/{MAX_RETRY}): {e}")
            await asyncio.sleep(wait)
    print(f"  âŒ OpenAI API å¤šæ¬¡å¤±è´¥{chunk_info}")
    return "ERROR: LLM å¤šæ¬¡å¤±è´¥"


async def call_llm_gemini(prompt, chunk_id=None):
    """è°ƒç”¨ Gemini API"""
    import google.generativeai as genai
    
    chunk_info = f" [å— {chunk_id}]" if chunk_id else ""
    
    # ä½¿ç”¨å…¨å±€å®‰å…¨è®¾ç½®ï¼Œå¦‚æœæœªè®¾ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼
    safety_settings = gemini_safety_settings
    
    for attempt in range(MAX_RETRY):
        try:
            if attempt == 0:
                print(f"  ğŸ”„ è°ƒç”¨ Gemini API{chunk_info}...")
            
            # è·å–æ¨¡å‹ï¼ˆæ¯æ¬¡è°ƒç”¨æ—¶é‡æ–°è·å–ï¼Œé¿å…çŠ¶æ€é—®é¢˜ï¼‰
            model = genai.GenerativeModel(MODEL_NAME)
            
            # Gemini API æ˜¯åŒæ­¥çš„ï¼Œéœ€è¦åœ¨å¼‚æ­¥ç¯å¢ƒä¸­è¿è¡Œ
            if safety_settings:
                response = await asyncio.get_event_loop().run_in_executor(
                    None,
                    lambda: model.generate_content(
                        prompt,
                        safety_settings=safety_settings
                    )
                )
            else:
                response = await asyncio.get_event_loop().run_in_executor(
                    None,
                    lambda: model.generate_content(prompt)
                )
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹è¢«é˜»æ­¢
            if hasattr(response, 'prompt_feedback') and response.prompt_feedback:
                feedback = response.prompt_feedback
                if hasattr(feedback, 'block_reason') and feedback.block_reason:
                    block_reason = feedback.block_reason.name if hasattr(feedback.block_reason, 'name') else str(feedback.block_reason)
                    error_msg = f"å†…å®¹è¢«é˜»æ­¢ (åŸå› : {block_reason})"
                    if hasattr(feedback, 'safety_ratings') and feedback.safety_ratings:
                        ratings_info = []
                        for rating in feedback.safety_ratings:
                            category = rating.category.name if hasattr(rating.category, 'name') else str(rating.category)
                            probability = rating.probability.name if hasattr(rating.probability, 'name') else str(rating.probability)
                            ratings_info.append(f"{category}: {probability}")
                        error_msg += f" [è¯¦æƒ…: {', '.join(ratings_info)}]"
                    
                    print(f"  âš ï¸ {error_msg}{chunk_info}")
                    # å¦‚æœè¢«é˜»æ­¢ï¼Œä¸é‡è¯•ï¼Œç›´æ¥è¿”å›é”™è¯¯ä¿¡æ¯
                    return f"ERROR: å†…å®¹è¢«å®‰å…¨è¿‡æ»¤å™¨é˜»æ­¢ - {error_msg}"
            
            # æå–æ–‡æœ¬å†…å®¹
            if hasattr(response, 'text') and response.text:
                print(f"  âœ… Gemini API è°ƒç”¨æˆåŠŸ{chunk_info}")
                return response.text
            else:
                # æ£€æŸ¥æ˜¯å¦æœ‰å€™é€‰å“åº”
                if hasattr(response, 'candidates') and response.candidates:
                    candidate = response.candidates[0]
                    if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                        text_parts = [part.text for part in candidate.content.parts if hasattr(part, 'text')]
                        if text_parts:
                            result = ''.join(text_parts)
                            print(f"  âœ… Gemini API è°ƒç”¨æˆåŠŸ{chunk_info}")
                            return result
                
                # å¦‚æœæ²¡æœ‰å€™é€‰å“åº”ï¼Œæ£€æŸ¥æ˜¯å¦è¢«é˜»æ­¢
                if hasattr(response, 'prompt_feedback'):
                    error_msg = "Gemini API è¿”å›ç©ºå†…å®¹ï¼ˆå¯èƒ½è¢«å®‰å…¨è¿‡æ»¤å™¨é˜»æ­¢ï¼‰"
                else:
                    error_msg = "Gemini API è¿”å›ç©ºå†…å®¹"
                raise ValueError(error_msg)
                
        except ValueError as e:
            # å¯¹äºå†…å®¹è¢«é˜»æ­¢çš„æƒ…å†µï¼Œä¸é‡è¯•
            if "è¢«å®‰å…¨è¿‡æ»¤å™¨é˜»æ­¢" in str(e) or "è¢«é˜»æ­¢" in str(e):
                print(f"  âŒ {str(e)}{chunk_info}")
                return f"ERROR: {str(e)}"
            raise
        except Exception as e:
            wait = (2 ** attempt) + random.random()
            error_detail = str(e)
            # æ£€æŸ¥æ˜¯å¦æ˜¯å†…å®¹è¢«é˜»æ­¢çš„é”™è¯¯
            if "PROHIBITED_CONTENT" in error_detail or "block_reason" in error_detail:
                print(f"  âš ï¸ å†…å®¹è¢«å®‰å…¨è¿‡æ»¤å™¨é˜»æ­¢{chunk_info}: {error_detail}")
                print(f"  ğŸ’¡ æç¤º: å¯ä»¥å°è¯•åœ¨ config.py ä¸­è°ƒæ•´ GEMINI_SAFETY_SETTINGS è®¾ç½®")
                # å¯¹äºå†…å®¹é˜»æ­¢ï¼Œä¸é‡è¯•
                return f"ERROR: å†…å®¹è¢«å®‰å…¨è¿‡æ»¤å™¨é˜»æ­¢ - {error_detail}"
            
            print(f"  âš ï¸ è°ƒç”¨å¤±è´¥{chunk_info}ï¼Œ{wait:.1f}s åé‡è¯• (å°è¯• {attempt + 1}/{MAX_RETRY}): {error_detail}")
            await asyncio.sleep(wait)
    
    print(f"  âŒ Gemini API å¤šæ¬¡å¤±è´¥{chunk_info}")
    return "ERROR: LLM å¤šæ¬¡å¤±è´¥"


async def call_llm(prompt, chunk_id=None):
    """ç»Ÿä¸€çš„ LLM è°ƒç”¨æ¥å£ï¼Œæ ¹æ®é…ç½®è‡ªåŠ¨é€‰æ‹© API"""
    if API_PROVIDER == "gemini":
        return await call_llm_gemini(prompt, chunk_id)
    else:
        return await call_llm_openai(prompt, chunk_id)
